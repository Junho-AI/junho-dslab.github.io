<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="https://junho-dslab.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://junho-dslab.github.io/" rel="alternate" type="text/html" /><updated>2022-03-02T19:10:04+09:00</updated><id>https://junho-dslab.github.io/feed.xml</id><title type="html">Keep Moving</title><subtitle>블로그</subtitle><author><name>Junho Shin</name></author><entry><title type="html">Text AutoAugment: Learning Compositional Augmentation Policy for Text Classification 논문 리뷰</title><link href="https://junho-dslab.github.io/emnlp2021,%20data%20augmentation/main/" rel="alternate" type="text/html" title="Text AutoAugment: Learning Compositional Augmentation Policy for Text Classification 논문 리뷰" /><published>2021-09-06T00:00:00+09:00</published><updated>2021-09-06T00:00:00+09:00</updated><id>https://junho-dslab.github.io/emnlp2021,%20data%20augmentation/main</id><content type="html" xml:base="https://junho-dslab.github.io/emnlp2021,%20data%20augmentation/main/">&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;데이터 증강은 적은 리소스 환경에서의 과적합 문제와 클래스 불균형 문제를 해결하기 위해 풍부한 학습 데이터 샘플 구축을 목표로 한다. 기존의 방법은 동의어 대체와 같은 분류하고자 하는 테스트에 맞게 최적화된 기법을 고안한 다음, 높은 성능을 높이는 하이퍼 파라미터를 인위적으로 설정하는 방식으로 이루어졌다. 하지만 이러한 방식은 많은 사전 지식이 필요하고, 차선책에 그칠 가능성이 있다. 게다가 증강 기법의 파라미터 수는 이전 연구들에 의해 제한적으로 정해질 수 있으며, 증강 데이터의 품질(다양성)이 떨어질 수 있고 성능 향상에 제약이 있을 수 있다. 이러한 문제를 해결하기 위해, 저자는 Text AutoAugment(TAA)라는 프레임워크를 제안한다. TAA는 데이터 증강을 위한 compositional하고 learnable한 패러다임이다. 이전 논문과의 차이점은 증강 정책(policy)에서의 다양한 기법들(operations)의 결합으로 간주하고, Bayesian Optimization 알고리즘을 활용한다. 또한 모델이 최적의 증강 파라미터를 찾도록 유도함으로써 모델의 일반화(generalization) 능력을 크게 향상시킨다. 저자의 방식은 데이터의 수가 부족하고, 클래스 데이터의 불균형이 있는 6개의 벤치마크 분류 성능에서 정확도를 평균 8.8%, 9.7% 향상시켰다.&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;텍스트 분류와 같은 자연어 처리 테스트에서의 모델 성능은 대부분 양질의 학습 데이터에 크게 의존한다. 그러나 이는 데이터를 구축함에 있어서 시간소모적(time-consuming)이며 노동집약적(labor-intensive)이며, 대부분은 적은 데이터 환경에서 진행될 수 밖에 없을 것이다. 데이터 증강은 분류 성능을 높이기 위한 row instances를 기반으로 하여, label를 변환하지 않는 선에서 추가적인 instance를 합성하는 방식으로 이루어진다. 이전 논문에서의 데이터 증강은 데이터가 불충분하고 불균형 클래스와 같은 다양한 시나리오에서의 우수함을 입증하는 방식으로 접근한다.&lt;/p&gt;

&lt;p&gt;이전 증강 방식은 크게 “생성”과 “수정”의 2가지로 나눌 수 있다. 생성 방식의 증강 방법들은 원본 문장에서 paraphrases를 통합하기 위해 조건부(conditional) 생성 모델을 사용한다 &lt;strong&gt;(원본 데이터셋의 표현 방식들을 최대한 유지하겠다라는 뜻으로 해석하였음)&lt;/strong&gt;. 이러한 방식은 문장의 유창함이나 라벨 보존성에서 장점을 가지고 있지만, GPT와 같은 대용량 모델을 fine-tuning하기에 부담감이 있다. 대신에 수정 방식의 증강 방법들은 삭제나 swap과 같은 기법들을 증강이 필요한 label(데이터 수가 적은)의 문장에 적용하는 방식이다. 이 방식은 거대 언어 모델을 학습 시킬 필요가 없이, 간단하고 효율적이다. 그러나 수정 방식의 단점은 얼마나 문장 내 단어를 바꿀 것인지 정하는 파라미터에 대해 예민하다 &lt;strong&gt;(EDA의 경우, 0.0~1.0에서 각자 학습 데이터에 맞는 적절한 수를 찾기에는 어렵다. 물론 추천하는 파라미터는 존재하지만).&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Figure 1를 보면, IMDB 데이터셋에 있어서 수정될 단어의 수를 정하는 여러 파라미터에 대해 분류 성능을 조사하였다. TF-IDF 대체 모델의 경우 0.4이하로 성능이 떨어짐을 확인하였다. 논문의 저자는 heuristic한 하이퍼 파라미터의 설정은 효율성이 떨어지고 차선책에 빠지기 쉽다고 언급하고 있다 &lt;strong&gt;(내 생각으로는 임의적으로 본인이 “0.6 이상이면 문장 내 다양한 단어로 많이 바뀔테니깐 성능이 높아지겠지?”라고 설정하게 되는 순간, 오히려 성능 하락으로 이어질 가능성이 크다고 주장하는 것 같다).&lt;/strong&gt; 게다가 다른 수정 방식의 논문들에서는 한 문장에 단 한번의 증강 기법을 적용하고 이것이 증강 문장 표현의 다양성을 하락시키며, 성능을 하락시킨다. &lt;strong&gt;(어느 한 문장은 일부 단어 몇개만 삭제해야 성능이 오르고, 다른 문장은 대체만 해야 성능이 오른다고 가정한다면, 모든 문장에 동일한 증강 기법(RS,RI,RD,SR과 같은)을 사용하면 안된다는 것으로 해석)&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sys&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;total&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arg&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:])&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'sum ='&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;total&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ValueError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'Please supply integer arguments'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;2장에서 논의할 분포의 역할들 중 하나는 한정된 수의 관찰 집합 $x_{1},…,x_{N}$이 주어졌을 때 확률 변수 $x$의 확률 분포 $p(x)$를 모델링하는 것이다.&lt;/p&gt;</content><author><name>Junho Shin</name></author><category term="EMNLP2021, Data Augmentation" /><category term="EMNLP2021" /><category term="Data Augmentation" /><summary type="html">EMNLP2021</summary></entry></feed>