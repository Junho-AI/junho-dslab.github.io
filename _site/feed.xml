<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="https://junho-dslab.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://junho-dslab.github.io/" rel="alternate" type="text/html" /><updated>2022-03-02T23:53:59+09:00</updated><id>https://junho-dslab.github.io/feed.xml</id><title type="html">Keep Moving</title><subtitle>블로그</subtitle><author><name>Junho Shin</name></author><entry><title type="html">Text AutoAugment: Learning Compositional Augmentation Policy for Text Classification 논문 리뷰</title><link href="https://junho-dslab.github.io/emnlp2021,%20data%20augmentation/main/" rel="alternate" type="text/html" title="Text AutoAugment: Learning Compositional Augmentation Policy for Text Classification 논문 리뷰" /><published>2021-09-06T00:00:00+09:00</published><updated>2021-09-06T00:00:00+09:00</updated><id>https://junho-dslab.github.io/emnlp2021,%20data%20augmentation/main</id><content type="html" xml:base="https://junho-dslab.github.io/emnlp2021,%20data%20augmentation/main/">&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;데이터 증강은 적은 리소스 환경에서의 과적합 문제와 클래스 불균형 문제를 해결하기 위해 풍부한 학습 데이터 샘플 구축을 목표로 한다. 기존의 방법은 동의어 대체와 같은 분류하고자 하는 테스트에 맞게 최적화된 기법을 고안한 다음, 높은 성능을 높이는 하이퍼 파라미터를 인위적으로 설정하는 방식으로 이루어졌다. 하지만 이러한 방식은 많은 사전 지식이 필요하고, 차선책에 그칠 가능성이 있다. 게다가 증강 기법의 파라미터 수는 이전 연구들에 의해 제한적으로 정해질 수 있으며, 증강 데이터의 품질(다양성)이 떨어질 수 있고 성능 향상에 제약이 있을 수 있다. 이러한 문제를 해결하기 위해, 저자는 Text AutoAugment(TAA)라는 프레임워크를 제안한다. TAA는 데이터 증강을 위한 compositional하고 learnable한 패러다임이다. 이전 논문과의 차이점은 증강 정책(policy)에서의 다양한 기법들(operations)의 결합으로 간주하고, Bayesian Optimization 알고리즘을 활용한다. 또한 모델이 최적의 증강 파라미터를 찾도록 유도함으로써 모델의 일반화(generalization) 능력을 크게 향상시킨다. 저자의 방식은 데이터의 수가 부족하고, 클래스 데이터의 불균형이 있는 6개의 벤치마크 분류 성능에서 정확도를 평균 8.8%, 9.7% 향상시켰다.&lt;/p&gt;

&lt;h2 id=&quot;1-introduction&quot;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;텍스트 분류와 같은 자연어 처리 테스트에서의 모델 성능은 대부분 양질의 학습 데이터에 크게 의존한다. 그러나 이는 데이터를 구축함에 있어서 시간소모적(time-consuming)이며 노동집약적(labor-intensive)이며, 대부분은 적은 데이터 환경에서 진행될 수 밖에 없을 것이다. 데이터 증강은 분류 성능을 높이기 위한 row instances를 기반으로 하여, label를 변환하지 않는 선에서 추가적인 instance를 합성하는 방식으로 이루어진다. 이전 논문에서의 데이터 증강은 데이터가 불충분하고 불균형 클래스와 같은 다양한 시나리오에서의 우수함을 입증하는 방식으로 접근한다.&lt;/p&gt;

&lt;p&gt;이전 증강 방식은 크게 “생성”과 “수정”의 2가지로 나눌 수 있다. 생성 방식의 증강 방법들은 원본 문장에서 paraphrases를 통합하기 위해 조건부(conditional) 생성 모델을 사용한다 &lt;strong&gt;(원본 데이터셋의 표현 방식들을 최대한 유지하겠다라는 뜻으로 해석하였음)&lt;/strong&gt;. 이러한 방식은 문장의 유창함이나 라벨 보존성에서 장점을 가지고 있지만, GPT와 같은 대용량 모델을 fine-tuning하기에 부담감이 있다. 대신에 수정 방식의 증강 방법들은 삭제나 swap과 같은 기법들을 증강이 필요한 label(데이터 수가 적은)의 문장에 적용하는 방식이다. 이 방식은 거대 언어 모델을 학습 시킬 필요가 없이, 간단하고 효율적이다. 그러나 수정 방식의 단점은 얼마나 문장 내 단어를 바꿀 것인지 정하는 파라미터에 대해 예민하다 &lt;strong&gt;(EDA의 경우, 0.0~1.0에서 각자 학습 데이터에 맞는 적절한 수를 찾기에는 어렵다. 물론 추천하는 파라미터는 존재하지만).&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/TAA_figure1.png&quot; alt=&quot;&quot; width=&quot;500&quot; height=&quot;500&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Figure 1를 보면, IMDB 데이터셋에 있어서 수정될 단어의 수를 정하는 여러 파라미터에 대해 분류 성능을 조사하였다. TF-IDF 대체 모델의 경우 0.4이하로 성능이 떨어짐을 확인하였다. 논문의 저자는 heuristic한 하이퍼 파라미터의 설정은 효율성이 떨어지고 차선책에 빠지기 쉽다고 언급하고 있다 &lt;strong&gt;(내 생각으로는 임의적으로 본인이 “0.6 이상이면 문장 내 다양한 단어로 많이 바뀔테니깐 성능이 높아지겠지?”라고 설정하게 되는 순간, 오히려 성능 하락으로 이어질 가능성이 크다고 주장하는 것 같다).&lt;/strong&gt; 게다가 다른 수정 방식의 논문들에서는 한 문장에 단 한번의 증강 기법을 적용하고 이것이 증강 문장 표현의 다양성을 하락시키며, 성능을 하락시킨다. &lt;strong&gt;(어느 한 문장은 일부 단어 몇개만 삭제해야 성능이 오르고, 다른 문장은 대체만 해야 성능이 오른다고 가정한다면, 모든 문장에 동일한 증강 기법(RS,RI,RD,SR과 같은)을 사용하면 안된다는 것으로 해석)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;이러한 문제를 극복하기 위해, 논문의 저자는 데이터 증강에 있어서 compositional하고 learnable한 패러다임인 Text AutoAugment(TAA) 프레임워크를 제안하였다. 저자의 목표는 분류 모델의 성능을 증가시키기 위해, 수정 방식 증강 방법에서 학습 데이터에 맞게 최선의 하이퍼 파라미터를 자동적으로 정하도록 하는 것이다. 저자는 증강 방식에서 사용될 policy 목록을 \(\{op_{1}, \cdots , op_{N}\}\) 와 같이 설정하였으며, \({op}\) 내부에는 \({type \;t,\;probability \;p,\;magnitude \; \lambda}\)의 3가지 파라미터가 존재한다. 다음과 같은 구도는 원본 문장에 대해 하나 이상의 operation을 적용할 수 있으며, systhetic instances의 다양성을 높일 수 있다. &lt;strong&gt;(policy안에 여러개의 \(op\)가 있기 때문에.)&lt;/strong&gt; 최종적으로 policy solution은 operation set과 각 operation에서의 수정 파라미터의 2가지 형태의 지식을 학습하게 된다. 저자는 최적의 policy를 찾기 위해, 새로운 objective function를 제안하고, Sequential Model-based Global Optimization (SMBO)를 사용했으며, 효율적이고 광범위하게 쓰이는 메소드인 AutoML를 최적의 policy를 학습하는데 사용하였다.&lt;/p&gt;

&lt;p&gt;저자의 알고리즘은 주어진 타겟 데이터셋에 적응(adaptively)하면서 자동적으로 최적의 증강 policy를 찾는다고 한다. 또한 distributed된 learning 프레임워크는 몇몇의 GPU 환경에서 기대할만한 결과를 얻을 수 있다고 한다. 요약하자면, 논문이 공헌할 수 있는 바는 크게 2개로 요약할 수 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;우리는 데이터 증강을 위한 learnable and compositional framework을 제안한다. 우리의 목적은 알고리즘이 자동적으로 최적의 compositional policy를 찾으며, 해당 policy는 증강된 데이터의 양과 질, 다양성을 향상시킨다.&lt;/li&gt;
  &lt;li&gt;적은 데이터 환경, 클래스 불균형 데이터 형태를 띄는 6개의 벤치마크 데이터셋에서, TAA는 BERT와 같은 Neural networks에서 generalization 성능을 상당히 많이 높일 수 있으며, 분류 성능 또한 효과적인 향상을 보였다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;2-text-autoaugment&quot;&gt;2. Text AutoAugment&lt;/h2&gt;
&lt;p&gt;이번 섹션에서는, TAA가 어떻게 최적의 증강 policy를 찾도록 동작하는지 소개한다. 첫번째로 TAA의 policy는 다양한 operation들의 조합으로 구성되어 있으며, 계층적인 구조를 띄고 있다. 자세한 설명은 Section 2.1에 나와있다. 두번째는 전체적인 개요와 global objective function에 대한 설명이며 Section 2.2에 있다. 마지막으로는 구체적인 policy optimization에 대해서 설명한다. 위에서 언급하였듯이 하나의 policy는 \({N}\)개의 다양한 operation으로 구성되어 있다.&lt;/p&gt;

&lt;h2 id=&quot;21-compositional-augmentation-policy&quot;&gt;2.1 Compositional Augmentation Policy&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;/assets/img/TAA_figure2.png&quot; alt=&quot;&quot; width=&quot;1000&quot; height=&quot;900&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;다양한 표현을 가진 증강 문장을 생성하기 위해, 저자는 하나의 operation 대신에 compositional policy를 소개한다. 
Figure2는 해당 policy \({\mathcal P}\)의 사용법에 대해서 보여준다.&lt;/p&gt;

&lt;div class=&quot;align-center&quot;&gt;\[{\mathcal P = {\{\mathcal O_{1}, \cdots ,\mathcal O_{i}, \cdots , \mathcal O_{N}\}}}\]
&lt;/div&gt;

&lt;p&gt;operation \({\mathcal O}\)는 atomic 구성 요소이며, 텍스트 \({x}\)를 증강된 문장 \({x_{aug}}\)로 만들어준다. 각 operation \({\mathcal O_{i}}\)는 위에서 또한 언급하였듯이 3개의 요소로 구성되어 있다.&lt;/p&gt;

\[{\mathcal O_{i} = \left\langle t_{i},p_{i},{\lambda_{i}} \right\rangle}\]

&lt;p&gt;3개의 파라미터에서 (1)&lt;/p&gt;

&lt;h2 id=&quot;ignore&quot;&gt;ignore&lt;/h2&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sys&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;total&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arg&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:])&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'sum ='&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;total&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ValueError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'Please supply integer arguments'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;2장에서 논의할 분포의 역할들 중 하나는 한정된 수의 관찰 집합 $x_{1},…,x_{N}$이 주어졌을 때 확률 변수 $x$의 확률 분포 $p(x)$를 모델링하는 것이다.&lt;/p&gt;</content><author><name>Junho Shin</name></author><category term="EMNLP2021, Data Augmentation" /><category term="EMNLP2021" /><category term="Data Augmentation" /><summary type="html">EMNLP2021</summary></entry></feed>